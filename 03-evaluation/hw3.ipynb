{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44914296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting minsearch\n",
      "  Downloading minsearch-0.0.4-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: qdrant_client in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (1.14.3)\n",
      "Requirement already satisfied: numpy in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from minsearch) (2.3.0)\n",
      "Collecting pandas (from minsearch)\n",
      "  Downloading pandas-2.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting scikit-learn (from minsearch)\n",
      "  Downloading scikit_learn-1.7.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from qdrant_client) (1.73.0)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.28.1)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from qdrant_client) (2.10.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from qdrant_client) (6.31.1)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from qdrant_client) (2.11.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from qdrant_client) (2.4.0)\n",
      "Requirement already satisfied: anyio in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (4.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (4.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from pandas->minsearch) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->minsearch)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->minsearch)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->minsearch) (1.17.0)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn->minsearch)\n",
      "  Downloading scipy-1.16.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->minsearch)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->minsearch)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading minsearch-0.0.4-py3-none-any.whl (11 kB)\n",
      "Downloading pandas-2.3.1-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading scikit_learn-1.7.0-cp311-cp311-macosx_12_0_arm64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.16.0-cp311-cp311-macosx_14_0_arm64.whl (20.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, scipy, joblib, scikit-learn, pandas, minsearch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [minsearch]/8\u001b[0m [pandas]learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.1 minsearch-0.0.4 pandas-2.3.1 pytz-2025.2 scikit-learn-1.7.0 scipy-1.16.0 threadpoolctl-3.6.0 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U minsearch qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e796ea6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'raw.githubusercontent.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'raw.githubusercontent.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for HTTP requests and data manipulation\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base URL for the dataset\n",
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "\n",
    "# Download the documents JSON file from the remote repository\n",
    "# 'verify=False' disables SSL certificate verification (useful for some environments)\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url, verify=False).json()\n",
    "\n",
    "# Import StringIO to read CSV content from a string\n",
    "from io import StringIO\n",
    "\n",
    "# Download the ground truth CSV file from the remote repository\n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "csv_content = requests.get(ground_truth_url, verify=False).text\n",
    "\n",
    "# Read the CSV content into a pandas DataFrame\n",
    "df_ground_truth = pd.read_csv(StringIO(csv_content))\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries for easier processing\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef34bd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import tqdm for progress bars\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Calculate hit rate: proportion of queries where the correct document is found in results\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "# Calculate Mean Reciprocal Rank (MRR): average reciprocal rank of the correct document in results\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "# Evaluate search function using ground truth data\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']  # Ground truth document ID\n",
    "        results = search_function(q)  # Search results for the query\n",
    "        relevance = [d['id'] == doc_id for d in results]  # List of booleans: True if result matches ground truth\n",
    "        relevance_total.append(relevance)\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67228183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [00:04<00:00, 1005.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate: 0.860\n",
      "MRR: 0.690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Q1. Minsearch text\n",
    "boost = {'question': 1.5, 'section': 0.1}\n",
    "\n",
    "# Evaluate minsearch with custom boosting parameters\n",
    "from minsearch import Index\n",
    "\n",
    "index = Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],   # Fields used for full-text search\n",
    "    keyword_fields=[]                      # Fields used for exact filters\n",
    ")\n",
    "index.fit(documents)\n",
    "\n",
    "def search_function(query):\n",
    "    results = index.search(\n",
    "        query['question'],\n",
    "        boost_dict=boost,\n",
    "        filter_dict={'course': query['course']}\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Calculate hit rate and MRR for this approach\n",
    "results = evaluate(ground_truth, search_function)\n",
    "print(f\"Hit rate: {results['hit_rate']:.3f}\")\n",
    "print(f\"MRR: {results['mrr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b01975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VectorSearch from minsearch and required sklearn modules\n",
    "from minsearch import VectorSearch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Prepare a list of questions from the documents for vectorization\n",
    "texts = []\n",
    "for doc in documents:\n",
    "    t = doc['question']  # Extract the question field\n",
    "    texts.append(t)\n",
    "\n",
    "# Create a pipeline: TF-IDF vectorizer followed by dimensionality reduction (SVD)\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),           # Vectorize text, ignore terms with low frequency\n",
    "    TruncatedSVD(n_components=128, random_state=1)  # Reduce to 128 dimensions\n",
    ")\n",
    "X = pipeline.fit_transform(texts)  # Fit and transform the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "390fa94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [00:02<00:00, 2021.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate: 0.561\n",
      "MRR: 0.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Q2. Vector search for question\n",
    "\n",
    "# Create a VectorSearch index using the reduced-dimension question vectors and documents\n",
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)\n",
    "\n",
    "# Define a search function for evaluation\n",
    "# For each query, transform the question using the same pipeline and search with vindex\n",
    "\n",
    "def search_function(q):\n",
    "    query_vec = pipeline.transform([q['question']])\n",
    "    return vindex.search(query_vec, filter_dict={'course': q['course']})  # Filter by course if needed\n",
    "\n",
    "# Evaluate the vector search method and print the MRR\n",
    "results = evaluate(ground_truth, search_function)\n",
    "print(f\"Hit rate: {results['hit_rate']:.3f}\")\n",
    "print(f\"MRR: {results['mrr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc99c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [00:02<00:00, 1611.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate: 0.842\n",
      "MRR: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Q3. Vector search for question and answer\n",
    "##We only used question in Q2. We can use both question and answer:\n",
    "\n",
    "texts = []\n",
    "for doc in documents:\n",
    "    t = doc['question'] + ' ' + doc['text']\n",
    "    texts.append(t)\n",
    "\n",
    "# Create a pipeline: TF-IDF vectorizer followed by dimensionality reduction (SVD)\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(texts)\n",
    "\n",
    "# Create a VectorSearch index using the combined question+answer vectors and documents\n",
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)\n",
    "\n",
    "# Define a search function for evaluation\n",
    "def search_function(q):\n",
    "    query_text = q['question'] + ' ' + q.get('text', '')\n",
    "    query_vec = pipeline.transform([query_text])[0]\n",
    "    return vindex.search(query_vec, filter_dict={'course': q['course']})\n",
    "\n",
    "# Evaluate the vector search method and print the MRR\n",
    "results = evaluate(ground_truth, search_function)\n",
    "print(f\"Hit rate: {results['hit_rate']:.3f}\")\n",
    "print(f\"MRR: {results['mrr']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q4. Qdrant\n",
    "\n",
    "# Import Qdrant client and embedding model\n",
    "from qdrant_client import QdrantClient, models\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "# Prepare texts: question + answer\n",
    "texts = [doc['question'] + ' ' + doc['text'] for doc in documents]\n",
    "\n",
    "# Use Jina embeddings model with fastembed\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "embedder = TextEmbedding(model_name=model_handle)\n",
    "\n",
    "# Generate embeddings for all texts\n",
    "embeddings = list(embedder.embed(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ff236f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Qdrant in-memory client\n",
    "client = QdrantClient(':memory:')\n",
    "\n",
    "# Create collection in Qdrant\n",
    "client.create_collection(\n",
    "    collection_name=\"docs\",\n",
    "    vectors_config=models.VectorParams(size=512, distance=\"Cosine\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "317bbfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload documents and vectors to Qdrant\n",
    "client.upload_collection(\n",
    "    collection_name=\"docs\",\n",
    "    vectors=embeddings,\n",
    "    payload=[doc for doc in documents],\n",
    "    ids=None,  # Let Qdrant auto-assign IDs\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f86bd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4627 [00:00<?, ?it/s]/var/folders/vd/dl48s8js5_z0k6_rb5jv19xw0000gn/T/ipykernel_69198/1269132691.py:6: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  hits = client.search(\n",
      "  0%|          | 1/4627 [00:00<11:32,  6.68it/s]/var/folders/vd/dl48s8js5_z0k6_rb5jv19xw0000gn/T/ipykernel_69198/1269132691.py:6: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  hits = client.search(\n",
      "100%|██████████| 4627/4627 [00:37<00:00, 123.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate: 0.930\n",
      "MRR: 0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define search function using Qdrant\n",
    "limit = 5\n",
    "def search_function(q):\n",
    "    query_text = q['question'] + ' ' + q.get('text', '')\n",
    "    query_vec = list(embedder.embed([query_text]))[0]\n",
    "    hits = client.search(\n",
    "        collection_name=\"docs\",\n",
    "        query_vector=query_vec,\n",
    "        limit=limit,\n",
    "        query_filter=models.Filter(must=[models.FieldCondition(key=\"course\", match=models.MatchValue(value=q['course']))])\n",
    "    )\n",
    "    return [hit.payload for hit in hits]\n",
    "\n",
    "# Evaluate and print results\n",
    "results = evaluate(ground_truth, search_function)\n",
    "print(f\"Hit rate: {results['hit_rate']:.3f}\")\n",
    "print(f\"MRR: {results['mrr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29797bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marinazdanova/DataTalks_LLM2025/DataCamp2025_LLM/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'raw.githubusercontent.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity: 0.84\n"
     ]
    }
   ],
   "source": [
    "## Q5. Cosine simiarity\n",
    "\n",
    "# Download results from gpt-4o-mini evaluations\n",
    "from io import StringIO\n",
    "results_url = url_prefix + 'rag_evaluation/data/results-gpt4o-mini.csv'\n",
    "csv_content = requests.get(results_url, verify=False).text\n",
    "df_results = pd.read_csv(StringIO(csv_content))\n",
    "\n",
    "# Fit the pipeline on all text data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "\n",
    "# Let's fit the vectorizer on all the text data we have:\n",
    "pipeline.fit(df_results.answer_llm + ' ' + df_results.answer_orig + ' ' + df_results.question)\n",
    "\n",
    "# Cosine similarity function\n",
    "import numpy as np\n",
    "def cosine(u, v):\n",
    "    u_norm = np.sqrt(u.dot(u))\n",
    "    v_norm = np.sqrt(v.dot(v))\n",
    "    return u.dot(v) / (u_norm * v_norm)\n",
    "\n",
    "# Calculate cosine similarity for each answer pair\n",
    "cosines = []\n",
    "for _, row in df_results.iterrows():\n",
    "    v_llm = pipeline.transform([row['answer_llm']])[0]\n",
    "    v_orig = pipeline.transform([row['answer_orig']])[0]\n",
    "    cos = cosine(v_llm, v_orig)\n",
    "    cosines.append(cos)\n",
    "\n",
    "# Print the average cosine similarity\n",
    "print(f\"Average cosine similarity: {np.mean(cosines):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb2120c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1 F1: 0.35\n"
     ]
    }
   ],
   "source": [
    "## Q6. Rouge\n",
    "\n",
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "rouge_1_f1_scores = []\n",
    "for _, row in df_results.iterrows():\n",
    "    scores = rouge_scorer.get_scores(row['answer_llm'], row['answer_orig'])[0]\n",
    "    rouge_1_f1_scores.append(scores['rouge-1']['f'])\n",
    "\n",
    "print(f\"Average ROUGE-1 F1: {np.mean(rouge_1_f1_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ce122bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>Some suggested titles for listing the Machine ...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>What are some suggested titles for listing the...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>It is best advised that you do not list the Ma...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Should I list the Machine Learning Zoomcamp ex...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>You can incorporate your Machine Learning Zoom...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>In which LinkedIn sections can I incorporate m...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>The advice on including a project link in a CV...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Who gave advice on including a project link in...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>The suggestion to showcase progress through Li...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Who suggested showcasing progress through Link...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1830 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answer_llm  \\\n",
       "0     You can sign up for the course by visiting the...   \n",
       "1     You can sign up using the link provided in the...   \n",
       "2     Yes, there is an FAQ for the Machine Learning ...   \n",
       "3     The context does not provide any specific info...   \n",
       "4     To structure your questions and answers for th...   \n",
       "...                                                 ...   \n",
       "1825  Some suggested titles for listing the Machine ...   \n",
       "1826  It is best advised that you do not list the Ma...   \n",
       "1827  You can incorporate your Machine Learning Zoom...   \n",
       "1828  The advice on including a project link in a CV...   \n",
       "1829  The suggestion to showcase progress through Li...   \n",
       "\n",
       "                                            answer_orig  document  \\\n",
       "0     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "...                                                 ...       ...   \n",
       "1825  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1826  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1827  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1828  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1829  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "\n",
       "                                               question  \\\n",
       "0                   Where can I sign up for the course?   \n",
       "1                    Can you provide a link to sign up?   \n",
       "2     Is there an FAQ for this Machine Learning course?   \n",
       "3     Does this course have a GitHub repository for ...   \n",
       "4     How can I structure my questions and answers f...   \n",
       "...                                                 ...   \n",
       "1825  What are some suggested titles for listing the...   \n",
       "1826  Should I list the Machine Learning Zoomcamp ex...   \n",
       "1827  In which LinkedIn sections can I incorporate m...   \n",
       "1828  Who gave advice on including a project link in...   \n",
       "1829  Who suggested showcasing progress through Link...   \n",
       "\n",
       "                         course  \n",
       "0     machine-learning-zoomcamp  \n",
       "1     machine-learning-zoomcamp  \n",
       "2     machine-learning-zoomcamp  \n",
       "3     machine-learning-zoomcamp  \n",
       "4     machine-learning-zoomcamp  \n",
       "...                         ...  \n",
       "1825  machine-learning-zoomcamp  \n",
       "1826  machine-learning-zoomcamp  \n",
       "1827  machine-learning-zoomcamp  \n",
       "1828  machine-learning-zoomcamp  \n",
       "1829  machine-learning-zoomcamp  \n",
       "\n",
       "[1830 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
